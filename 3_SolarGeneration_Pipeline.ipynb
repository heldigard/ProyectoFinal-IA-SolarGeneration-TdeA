{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se crea el pipeline necesario para poder guardar el modelo y utilizarlo posteriormente con la API que despliegue un endpoint para realizar las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos y los visualizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODULE_TEMP</th>\n",
       "      <th>Amb_Temp</th>\n",
       "      <th>WIND_Speed</th>\n",
       "      <th>IRR (W/m2)</th>\n",
       "      <th>DC Current in Amps</th>\n",
       "      <th>AC Ir in Amps</th>\n",
       "      <th>AC Iy in Amps</th>\n",
       "      <th>AC Ib in Amps</th>\n",
       "      <th>AC Power in Watts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.7675</td>\n",
       "      <td>17.85190</td>\n",
       "      <td>47.60506</td>\n",
       "      <td>6.388252</td>\n",
       "      <td>0.60</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.6150</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>64.26684</td>\n",
       "      <td>12.776500</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.9200</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>85.68912</td>\n",
       "      <td>17.035340</td>\n",
       "      <td>4.74</td>\n",
       "      <td>11.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.9200</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>83.30886</td>\n",
       "      <td>25.553010</td>\n",
       "      <td>8.18</td>\n",
       "      <td>14.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0725</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>57.12608</td>\n",
       "      <td>36.200090</td>\n",
       "      <td>26.66</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MODULE_TEMP  Amb_Temp  WIND_Speed  IRR (W/m2)  DC Current in Amps  \\\n",
       "0      18.7675  17.85190    47.60506    6.388252                0.60   \n",
       "1      18.6150  18.59573    64.26684   12.776500                0.66   \n",
       "2      18.9200  18.59573    85.68912   17.035340                4.74   \n",
       "3      18.9200  18.59573    83.30886   25.553010                8.18   \n",
       "4      19.0725  18.59573    57.12608   36.200090               26.66   \n",
       "\n",
       "   AC Ir in Amps  AC Iy in Amps  AC Ib in Amps  AC Power in Watts  \n",
       "0            8.6            8.6            8.7               3233  \n",
       "1            9.6            9.7           10.0               4504  \n",
       "2           11.9           12.0           12.4               6614  \n",
       "3           14.8           14.7           14.7               8971  \n",
       "4           18.6           18.4           18.5              12071  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Generation_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODULE_TEMP</th>\n",
       "      <th>Amb_Temp</th>\n",
       "      <th>IRR (W/m2)</th>\n",
       "      <th>AC Power in Watts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.7675</td>\n",
       "      <td>17.85190</td>\n",
       "      <td>6.388252</td>\n",
       "      <td>3233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.6150</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>12.776500</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.9200</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>17.035340</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.9200</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>25.553010</td>\n",
       "      <td>8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0725</td>\n",
       "      <td>18.59573</td>\n",
       "      <td>36.200090</td>\n",
       "      <td>12071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MODULE_TEMP  Amb_Temp  IRR (W/m2)  AC Power in Watts\n",
       "0      18.7675  17.85190    6.388252               3233\n",
       "1      18.6150  18.59573   12.776500               4504\n",
       "2      18.9200  18.59573   17.035340               6614\n",
       "3      18.9200  18.59573   25.553010               8971\n",
       "4      19.0725  18.59573   36.200090              12071"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mantener solo las columnas relevantes\n",
    "df = df[['MODULE_TEMP', 'Amb_Temp', 'IRR (W/m2)', 'AC Power in Watts']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar las variables en X y Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = df[[\"MODULE_TEMP\", \"Amb_Temp\", \"IRR (W/m2)\"]]\n",
    "y = df[\"AC Power in Watts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir el dataset en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU está disponible. Usando GPU: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Detectar si hay GPU disponible\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"GPU está disponible. Usando GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"GPU no está disponible. Usando CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar el Pipeline con el mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo en nuestro caso fue el modelo de LightGBM. Aquí están las métricas de los modelos entrenados actualizadas:\n",
    "\n",
    "- **Linear Regression**:\n",
    "  - Mean Squared Error: 159747971.16967878\n",
    "  - R^2 Score: 0.9808629271950605\n",
    "  - Mean Absolute Error: 7473.24538237479\n",
    "  - Median Absolute Error: 4958.310957427253\n",
    "\n",
    "- **Polynomial Regression**:\n",
    "  - Mean Squared Error: 140500997.19574532\n",
    "  - R^2 Score: 0.9831686262253331\n",
    "  - Mean Absolute Error: 6821.709353959054\n",
    "  - Median Absolute Error: 4211.522203715169\n",
    "\n",
    "- **Random Forest**:\n",
    "  - Mean Squared Error: 163281125.82455277\n",
    "  - R^2 Score: 0.9804396715044476\n",
    "  - Mean Absolute Error: 7449.578253928051\n",
    "  - Median Absolute Error: 4566.7236507936905\n",
    "\n",
    "- **Best Random Forest**:\n",
    "  - Mean Squared Error: 135551253.0213555\n",
    "  - R^2 Score: 0.9837615828302749\n",
    "  - Mean Absolute Error: 6606.933817275343\n",
    "  - Median Absolute Error: 4125.318189967948\n",
    "\n",
    "- **XGBoost**:\n",
    "  - Mean Squared Error: 137778087.35706922\n",
    "  - R^2 Score: 0.9834948182106018\n",
    "  - Mean Absolute Error: 6579.549506271723\n",
    "  - Median Absolute Error: 4019.5625\n",
    "\n",
    "- **LightGBM**:\n",
    "  - Mean Squared Error: **133961829.8498358**\n",
    "  - R^2 Score: **0.983951988421836**\n",
    "  - Mean Absolute Error: **6521.984914138249**\n",
    "  - Median Absolute Error: **4032.6299075853167**\n",
    "\n",
    "- **SVM**:\n",
    "  - Mean Squared Error: **6096543796.479938**\n",
    "  - R^2 Score: **0.2696620705885764**\n",
    "  - Mean Absolute Error: **64262.76685718178**\n",
    "  - Median Absolute Error: **58646.782756845016**\n",
    "\n",
    "El modelo de LightGBM tiene el menor Mean Squared Error (**133961829.8498358**) y un alto R^2 Score (**0.983951988421836**), lo que indica que es el mejor modelo para nuestro caso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear el Pipeline y Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque de código, vamos a crear un pipeline y entrenar un modelo utilizando LightGBM, \n",
    "ya que previamente hemos determinado que este algoritmo ofrece el mejor rendimiento. \n",
    "Además, vamos a experimentar con diferentes técnicas de escalamiento de variables y realizar \n",
    "una búsqueda de hiperparámetros para optimizar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 544\n",
      "[LightGBM] [Info] Number of data points in the train set: 95092, number of used features: 3\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 3 dense feature groups (0.36 MB) transferred to GPU in 0.001518 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 127979.374890\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "New best model saved with score: -146263011.82586992 and scaler: MinMaxScaler()\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 545\n",
      "[LightGBM] [Info] Number of data points in the train set: 95092, number of used features: 3\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 3 dense feature groups (0.36 MB) transferred to GPU in 0.000862 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 127979.374890\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 544\n",
      "[LightGBM] [Info] Number of data points in the train set: 95092, number of used features: 3\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 3 dense feature groups (0.36 MB) transferred to GPU in 0.001103 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 127979.374890\n",
      "Best Scaler: MinMaxScaler()\n",
      "Best Parameters: {'model__num_leaves': 31, 'model__n_estimators': 200, 'model__min_child_samples': 50, 'model__max_depth': 40, 'model__learning_rate': 0.05}\n",
      "Mean Squared Error (Pipeline): 133954591.3241406\n",
      "R^2 Score (Pipeline): 0.9839528555639486\n",
      "Mean Absolute Error (Pipeline): 6512.437414794143\n",
      "Median Absolute Error (Pipeline): 4030.7971097785685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Definir el pipeline con diferentes scalers\n",
    "scalers = [MinMaxScaler(), StandardScaler(), RobustScaler()]\n",
    "best_score = float('inf')\n",
    "best_pipeline = None\n",
    "best_scaler = None\n",
    "\n",
    "# Definir un rango más amplio y detallado de hiperparámetros\n",
    "param_grid = {\n",
    "  'model__num_leaves': [31, 50, 70, 100, 150],\n",
    "  'model__learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "  'model__n_estimators': [100, 200, 300, 400, 500],\n",
    "  'model__max_depth': [-1, 10, 20, 30, 40],\n",
    "  'model__min_child_samples': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "for scaler in scalers:\n",
    "  pipeline = Pipeline(\n",
    "    [\n",
    "      (\"scaler\", scaler),\n",
    "      (\"model\", lgb.LGBMRegressor(device='gpu', random_state=42))\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  # Configurar RandomizedSearchCV\n",
    "  random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, n_iter=50)\n",
    "\n",
    "  # Entrenar el pipeline con búsqueda de hiperparámetros\n",
    "  random_search.fit(X_train, y_train)\n",
    "  if random_search.best_score_ < best_score:\n",
    "    best_score = random_search.best_score_\n",
    "    best_pipeline = random_search.best_estimator_\n",
    "    best_scaler = scaler\n",
    "    joblib.dump(best_pipeline, \"best_model_pipeline.pkl\")\n",
    "    print(f\"New best model saved with score: {best_score} and scaler: {scaler}\")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_pipeline = joblib.load(\"best_model_pipeline.pkl\")\n",
    "\n",
    "# Hacer predicciones con el mejor modelo\n",
    "y_pred_pipeline = best_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "mse_pipeline = mean_squared_error(y_test, y_pred_pipeline)\n",
    "r2_pipeline = r2_score(y_test, y_pred_pipeline)\n",
    "mae_pipeline = mean_absolute_error(y_test, y_pred_pipeline)\n",
    "medae_pipeline = median_absolute_error(y_test, y_pred_pipeline)\n",
    "\n",
    "print(f\"Best Scaler: {best_scaler}\")\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "print(f\"Mean Squared Error (Pipeline): {mse_pipeline}\")\n",
    "print(f\"R^2 Score (Pipeline): {r2_pipeline}\")\n",
    "print(f\"Mean Absolute Error (Pipeline): {mae_pipeline}\")\n",
    "print(f\"Median Absolute Error (Pipeline): {medae_pipeline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el pipeline con el mejor modelo\n",
    "joblib.dump(best_pipeline, \"best_model_pipeline.pkl\")\n",
    "\n",
    "print(\"Modelo guardado exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "En este notebook, hemos desarrollado un pipeline para entrenar y guardar un modelo de predicción utilizando LightGBM. A continuación, se resumen los resultados obtenidos:\n",
    "\n",
    "- **Mejor modelo**: LightGBM\n",
    "- **Mejor escalador**: MinMaxScaler\n",
    "- **Mejores hiperparámetros**:\n",
    "  - `model__num_leaves`: 31\n",
    "  - `model__n_estimators`: 200\n",
    "  - `model__min_child_samples`: 50\n",
    "  - `model__max_depth`: 40\n",
    "  - `model__learning_rate`: 0.05\n",
    "\n",
    "## Métricas del mejor modelo:\n",
    "- **Mean Squared Error (MSE)**: 133,954,591.3241406\n",
    "- **R^2 Score**: 0.9839528555639486\n",
    "- **Mean Absolute Error (MAE)**: 6,512.437414794143\n",
    "- **Median Absolute Error (MedAE)**: 4,030.7971097785685\n",
    "\n",
    "El modelo de LightGBM entrenado con los hiperparámetros óptimos y utilizando MinMaxScaler como técnica de escalamiento ha demostrado ser el más efectivo, logrando un alto R^2 Score y bajos errores absolutos y cuadrados medios. Además, el uso de GPU (NVIDIA GeForce RTX 3060) ha permitido acelerar el proceso de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
